{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pieces:\n",
    "\n",
    "WP1:8\n",
    "WR1:2\n",
    "WK1:2\n",
    "WB1:2\n",
    "WQ\n",
    "WK\n",
    "\n",
    "BP1:8\n",
    "BR1:2\n",
    "BK1:2\n",
    "BB1:2\n",
    "BQ\n",
    "BK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "WP1 = torch.randn(1000)\n",
    "WP2 = torch.randn(1000)\n",
    "WP3 = torch.randn(1000)\n",
    "WP4 = torch.randn(1000)\n",
    "WP5 = torch.randn(1000)\n",
    "WP6 = torch.randn(1000)\n",
    "WP7 = torch.randn(1000)\n",
    "WP8 = torch.randn(1000)\n",
    "\n",
    "WR1 = torch.randn(1000)\n",
    "WR2 = torch.randn(1000)\n",
    "\n",
    "WN1 = torch.randn(1000)\n",
    "WN2 = torch.randn(1000)\n",
    "\n",
    "WB1 = torch.randn(1000)\n",
    "WB2 = torch.randn(1000) \n",
    "\n",
    "WQ = torch.randn(1000)\n",
    "WK = torch.randn(1000)\n",
    "\n",
    "BP1 = torch.randn(1000)\n",
    "BP2 = torch.randn(1000)\n",
    "BP3 = torch.randn(1000)\n",
    "BP4 = torch.randn(1000)\n",
    "BP5 = torch.randn(1000)\n",
    "BP6 = torch.randn(1000)\n",
    "BP7 = torch.randn(1000)\n",
    "BP8 = torch.randn(1000)\n",
    "\n",
    "BR1 = torch.randn(1000)\n",
    "BR2 = torch.randn(1000)\n",
    "\n",
    "BN1 = torch.randn(1000)\n",
    "BN2 = torch.randn(1000)\n",
    "\n",
    "BB1 = torch.randn(1000)\n",
    "BB2 = torch.randn(1000)\n",
    "\n",
    "BQ = torch.randn(1000)\n",
    "BK = torch.randn(1000)   \n",
    "\n",
    "E = torch.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define each row using lists of piece vectors (each of shape [1000])\n",
    "row1 = [WR1, WN1, WB1, WQ, WK, WB2, WN2, WR2]\n",
    "row2 = [WP1, WP2, WP3, WP4, WP5, WP6, WP7, WP8]\n",
    "row3 = [E] * 8\n",
    "row4 = [E] * 8\n",
    "row5 = [E] * 8\n",
    "row6 = [E] * 8\n",
    "row7 = [BP1, BP2, BP3, BP4, BP5, BP6, BP7, BP8]\n",
    "row8 = [BR1, BN1, BB1, BQ, BK, BB2, BN2, BR2]\n",
    "\n",
    "# Stack all rows into one flat list, then stack into a 64x1000 tensor\n",
    "board_rows = [row1, row2, row3, row4, row5, row6, row7, row8]\n",
    "current_board = torch.stack([piece for row in board_rows for piece in row])  # shape: [64, 1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1000])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_board.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryW = torch.randn([1000, 1000])\n",
    "keyW = torch.randn([1000, 1000])\n",
    "valueW = torch.randn([1000, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = current_board @ queryW\n",
    "key_embeddings = current_board @ keyW\n",
    "value_embeddings = current_board @ valueW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_emb = (query_embeddings @ key_embeddings.T) + value_embeddings\n",
    "final_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(torch.softmax(final_emb.reshape([64**2]), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import torch\n",
    "\n",
    "# ---------------------- 1. piece‑name ↔ vector lookup ----------------------\n",
    "piece_vecs = {\n",
    "    # white\n",
    "    \"WP1\": WP1, \"WP2\": WP2, \"WP3\": WP3, \"WP4\": WP4,\n",
    "    \"WP5\": WP5, \"WP6\": WP6, \"WP7\": WP7, \"WP8\": WP8,\n",
    "    \"WR1\": WR1, \"WR2\": WR2,\n",
    "    \"WK1\": WN1, \"WK2\": WN2,             # knights (you called them WK*)\n",
    "    \"WB1\": WB1, \"WB2\": WB2,\n",
    "    \"WQ\" : WQ , \"WK\" : WK,              # king\n",
    "    # black\n",
    "    \"BP1\": BP1, \"BP2\": BP2, \"BP3\": BP3, \"BP4\": BP4,\n",
    "    \"BP5\": BP5, \"BP6\": BP6, \"BP7\": BP7, \"BP8\": BP8,\n",
    "    \"BR1\": BR1, \"BR2\": BR2,\n",
    "    \"BK1\": BN1, \"BK2\": BN2,             # knights (you called them BK*)\n",
    "    \"BB1\": BB1, \"BB2\": BB2,\n",
    "    \"BQ\" : BQ , \"BK\" : BK,              # king\n",
    "}\n",
    "EMPTY = E                              # 1 000‑d “empty‑square” vector\n",
    "\n",
    "# Initial piece‑ID placement (square numbers are 0=a1 … 63=h8, python‑chess style)\n",
    "initial_map = {\n",
    "    # white back rank\n",
    "    0: \"WR1\", 1: \"WN1\", 2: \"WB1\", 3: \"WQ\", 4: \"WK\", 5: \"WB2\", 6: \"WN2\", 7: \"WR2\",\n",
    "    # white pawns\n",
    "    8: \"WP1\", 9: \"WP2\", 10: \"WP3\", 11: \"WP4\",\n",
    "    12: \"WP5\", 13: \"WP6\", 14: \"WP7\", 15: \"WP8\",\n",
    "    # black pawns\n",
    "    48: \"BP1\", 49: \"BP2\", 50: \"BP3\", 51: \"BP4\",\n",
    "    52: \"BP5\", 53: \"BP6\", 54: \"BP7\", 55: \"BP8\",\n",
    "    # black back rank\n",
    "    56: \"BR1\", 57: \"BN1\", 58: \"BB1\", 59: \"BQ\",\n",
    "    60: \"BK\",  61: \"BB2\", 62: \"BN2\", 63: \"BR2\",\n",
    "}\n",
    "\n",
    "# ---------------------- 2. helper: mapping ➜ 64×1000 tensor ---------------\n",
    "def mapping_to_tensor(square2id: dict) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    square2id : {square_idx: piece_id_name}\n",
    "    returns   : torch.Tensor[64, 1000]\n",
    "    \"\"\"\n",
    "    vecs = [piece_vecs.get(square2id.get(sq, None), EMPTY) for sq in range(64)]\n",
    "    return torch.stack(vecs)     # [64, 1000]\n",
    "\n",
    "# ---------------------- 4. aggregate many games ---------------------------\n",
    "def games_to_tensor_dataset(game_dicts: list[dict]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Flattens every board‑state from every game into one big tensor:\n",
    "        shape = [num_positions , 64 , 1000]\n",
    "    \"\"\"\n",
    "    all_states = []\n",
    "    for g in game_dicts:\n",
    "        all_states.extend(game_to_board_tensors(g))\n",
    "    return torch.stack(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "games = [{'Event': 'Rated Classical game',\n",
    " 'Site': 'https://lichess.org/j1dkb5dw',\n",
    " 'White': 'BFG9k',\n",
    " 'Black': 'mamalak',\n",
    " 'Result': '1-0',\n",
    " 'WhiteTitle': None,\n",
    " 'BlackTitle': None,\n",
    " 'WhiteElo': 1639,\n",
    " 'BlackElo': 1403,\n",
    " 'WhiteRatingDiff': 5,\n",
    " 'BlackRatingDiff': -8,\n",
    " 'UTCDate': datetime.date(2012, 12, 31),\n",
    " 'UTCTime': datetime.time(23, 1, 3),\n",
    " 'ECO': 'C00',\n",
    " 'Opening': 'French Defense: Normal Variation',\n",
    " 'Termination': 'Normal',\n",
    " 'TimeControl': '600+8',\n",
    " 'movetext': '1. e4 e6 2. d4 b6 3. a3 Bb7 4. Nc3 Nh6 5. Bxh6 gxh6 6. Be2 Qg5 7. Bg4 h5 8. Nf3 Qg6 9. Nh4 Qg5 10. Bxh5 Qxh4 11. Qf3 Kd8 12. Qxf7 Nc6 13. Qe8# 1-0'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import chess\n",
    "import torch\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 1.  TOKEN CLEAN‑UP  – turn raw movetext into a pure SAN generator  #\n",
    "# ------------------------------------------------------------------ #\n",
    "_move_num = re.compile(r\"^\\d+\\.(\\.\\.)?$\")   # matches “1.” or “1...”\n",
    "\n",
    "def san_stream(movetext: str):\n",
    "    \"\"\"\n",
    "    Yields pure SAN moves from a movetext string that may contain:\n",
    "      * move numbers  (1.  5...  12.)\n",
    "      * game results  (1-0  0-1  1/2-1/2  *)\n",
    "    \"\"\"\n",
    "    for tok in movetext.replace(\"\\n\", \" \").split():\n",
    "        if _move_num.match(tok) or tok in {\"1-0\", \"0-1\", \"1/2-1/2\", \"*\"}:\n",
    "            continue\n",
    "        yield tok\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 2.  game_to_board_tensors – same logic, but call the new san_stream #\n",
    "# ------------------------------------------------------------------ #\n",
    "def game_to_board_tensors(game_dict) -> list[torch.Tensor]:\n",
    "    board   = chess.Board()\n",
    "    mapping = initial_map.copy()\n",
    "    tensors = [mapping_to_tensor(mapping)]\n",
    "\n",
    "    for san in san_stream(game_dict[\"movetext\"]):\n",
    "        move = board.parse_san(san)\n",
    "\n",
    "        from_sq, to_sq = move.from_square, move.to_square\n",
    "        moving_id = mapping.pop(from_sq)           # leave origin\n",
    "\n",
    "        # capture on target square (regular or promotion capture)\n",
    "        if to_sq in mapping:\n",
    "            mapping.pop(to_sq)\n",
    "\n",
    "        # ---------- en‑passant (ask the board, not the move) ----------\n",
    "        if board.is_en_passant(move):\n",
    "            ep_target = to_sq + (-8 if board.turn else 8)\n",
    "            mapping.pop(ep_target, None)\n",
    "\n",
    "        mapping[to_sq] = moving_id                 # land piece\n",
    "\n",
    "        # ---------- castling (again, ask the board) -------|---\n",
    "        if board.is_castling(move):\n",
    "            if chess.square_file(to_sq) == chess.GFILE:   # king‑side 0‑0\n",
    "                rook_from, rook_to = (chess.H1, chess.F1) if board.turn else (chess.H8, chess.F8)\n",
    "            else:                                         # queen‑side 0‑0‑0\n",
    "                rook_from, rook_to = (chess.A1, chess.D1) if board.turn else (chess.A8, chess.D8)\n",
    "            mapping[rook_to] = mapping.pop(rook_from)\n",
    "\n",
    "        board.push(move)    \n",
    "        print(board)\n",
    "        print(' ' * 20)\n",
    "        tensors.append(mapping_to_tensor(mapping))\n",
    "\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "                    \n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . p . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "                    \n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . p . . .\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "                    \n",
      "r n b q k b n r\n",
      "p . p p . p p p\n",
      ". p . . p . . .\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "                    \n",
      "r n b q k b n r\n",
      "p . p p . p p p\n",
      ". p . . p . . .\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      "P . . . . . . .\n",
      ". P P . . P P P\n",
      "R N B Q K B N R\n",
      "                    \n",
      "r n . q k b n r\n",
      "p b p p . p p p\n",
      ". p . . p . . .\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      "P . . . . . . .\n",
      ". P P . . P P P\n",
      "R N B Q K B N R\n",
      "                    \n",
      "r n . q k b n r\n",
      "p b p p . p p p\n",
      ". p . . p . . .\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . B Q K B N R\n",
      "                    \n",
      "r n . q k b . r\n",
      "p b p p . p p p\n",
      ". p . . p . . n\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . B Q K B N R\n",
      "                    \n",
      "r n . q k b . r\n",
      "p b p p . p p p\n",
      ". p . . p . . B\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . Q K B N R\n",
      "                    \n",
      "r n . q k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . p\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . Q K B N R\n",
      "                    \n",
      "r n . q k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . p\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      "P . N . . . . .\n",
      ". P P . B P P P\n",
      "R . . Q K . N R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . p\n",
      ". . . . . . q .\n",
      ". . . P P . . .\n",
      "P . N . . . . .\n",
      ". P P . B P P P\n",
      "R . . Q K . N R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . p\n",
      ". . . . . . q .\n",
      ". . . P P . B .\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . Q K . N R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . .\n",
      ". . . . . . q p\n",
      ". . . P P . B .\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . Q K . N R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . .\n",
      ". . . . . . q p\n",
      ". . . P P . B .\n",
      "P . N . . N . .\n",
      ". P P . . P P P\n",
      "R . . Q K . . R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . q .\n",
      ". . . . . . . p\n",
      ". . . P P . B .\n",
      "P . N . . N . .\n",
      ". P P . . P P P\n",
      "R . . Q K . . R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . q .\n",
      ". . . . . . . p\n",
      ". . . P P . B N\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . Q K . . R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . .\n",
      ". . . . . . q p\n",
      ". . . P P . B N\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . Q K . . R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . .\n",
      ". . . . . . q B\n",
      ". . . P P . . N\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . Q K . . R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . q\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . Q K . . R\n",
      "                    \n",
      "r n . . k b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . q\n",
      "P . N . . Q . .\n",
      ". P P . . P P P\n",
      "R . . . K . . R\n",
      "                    \n",
      "r n . k . b . r\n",
      "p b p p . p . p\n",
      ". p . . p . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . q\n",
      "P . N . . Q . .\n",
      ". P P . . P P P\n",
      "R . . . K . . R\n",
      "                    \n",
      "r n . k . b . r\n",
      "p b p p . Q . p\n",
      ". p . . p . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . q\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . . K . . R\n",
      "                    \n",
      "r . . k . b . r\n",
      "p b p p . Q . p\n",
      ". p n . p . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . q\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . . K . . R\n",
      "                    \n",
      "r . . k Q b . r\n",
      "p b p p . . . p\n",
      ". p n . p . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . q\n",
      "P . N . . . . .\n",
      ". P P . . P P P\n",
      "R . . . K . . R\n",
      "                    \n",
      "torch.Size([26, 64, 1000])\n"
     ]
    }
   ],
   "source": [
    "board_tensors = games_to_tensor_dataset(games)\n",
    "print(board_tensors.shape)   # (total_positions, 64, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

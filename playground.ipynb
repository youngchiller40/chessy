{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pieces:\n",
    "\n",
    "WP1:8\n",
    "WR1:2\n",
    "WK1:2\n",
    "WB1:2\n",
    "WQ\n",
    "WK\n",
    "\n",
    "BP1:8\n",
    "BR1:2\n",
    "BK1:2\n",
    "BB1:2\n",
    "BQ\n",
    "BK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WP1 = torch.randn(1000)\n",
    "WP2 = torch.randn(1000)\n",
    "WP3 = torch.randn(1000)\n",
    "WP4 = torch.randn(1000)\n",
    "WP5 = torch.randn(1000)\n",
    "WP6 = torch.randn(1000)\n",
    "WP7 = torch.randn(1000)\n",
    "WP8 = torch.randn(1000)\n",
    "\n",
    "WR1 = torch.randn(1000)\n",
    "WR2 = torch.randn(1000)\n",
    "\n",
    "WK1 = torch.randn(1000)\n",
    "WK2 = torch.randn(1000)\n",
    "\n",
    "WB1 = torch.randn(1000)\n",
    "WB2 = torch.randn(1000) \n",
    "\n",
    "WQ = torch.randn(1000)\n",
    "WK = torch.randn(1000)\n",
    "\n",
    "BP1 = torch.randn(1000)\n",
    "BP2 = torch.randn(1000)\n",
    "BP3 = torch.randn(1000)\n",
    "BP4 = torch.randn(1000)\n",
    "BP5 = torch.randn(1000)\n",
    "BP6 = torch.randn(1000)\n",
    "BP7 = torch.randn(1000)\n",
    "BP8 = torch.randn(1000)\n",
    "\n",
    "BR1 = torch.randn(1000)\n",
    "BR2 = torch.randn(1000)\n",
    "\n",
    "BK1 = torch.randn(1000)\n",
    "BK2 = torch.randn(1000)\n",
    "\n",
    "BB1 = torch.randn(1000)\n",
    "BB2 = torch.randn(1000)\n",
    "\n",
    "BQ = torch.randn(1000)\n",
    "BK = torch.randn(1000)   \n",
    "\n",
    "E = torch.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define each row using lists of piece vectors (each of shape [1000])\n",
    "row1 = [WR1, WK1, WB1, WQ, WK, WB2, WK2, WR2]\n",
    "row2 = [WP1, WP2, WP3, WP4, WP5, WP6, WP7, WP8]\n",
    "row3 = [E] * 8\n",
    "row4 = [E] * 8\n",
    "row5 = [E] * 8\n",
    "row6 = [E] * 8\n",
    "row7 = [BP1, BP2, BP3, BP4, BP5, BP6, BP7, BP8]\n",
    "row8 = [BR1, BK1, BB1, BQ, BK, BB2, BK2, BR2]\n",
    "\n",
    "# Stack all rows into one flat list, then stack into a 64x1000 tensor\n",
    "board_rows = [row1, row2, row3, row4, row5, row6, row7, row8]\n",
    "current_board = torch.stack([piece for row in board_rows for piece in row])  # shape: [64, 1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1000])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_board.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryW = torch.randn([1000, 1000])\n",
    "keyW = torch.randn([1000, 1000])\n",
    "valueW = torch.randn([1000, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = current_board @ queryW\n",
    "key_embeddings = current_board @ keyW\n",
    "value_embeddings = current_board @ valueW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_emb = (query_embeddings @ key_embeddings.T) + value_embeddings\n",
    "final_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(torch.softmax(final_emb.reshape([64**2]), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
